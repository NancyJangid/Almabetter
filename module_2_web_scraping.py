# -*- coding: utf-8 -*-
"""Module 2 - Web Scraping.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yMsE-ynF8jcam1MIy4OiFdxyLKRDpet8

# **Web Scraping & Data Handling Challenge**

### **Website:**
JustWatch -  https://www.justwatch.com/in/movies?release_year_from=2000


### **Description:**

JustWatch is a popular platform that allows users to search for movies and TV shows across multiple streaming services like Netflix, Amazon Prime, Hulu, etc. For this assignment, you will be required to scrape movie and TV show data from JustWatch using Selenium, Python, and BeautifulSoup. Extract data from HTML, not by directly calling their APIs. Then, perform data filtering and analysis using Pandas, and finally, save the results to a CSV file.

### **Tasks:**

**1. Web Scraping:**

Use BeautifulSoup to scrape the following data from JustWatch:

   **a. Movie Information:**

      - Movie title
      - Release year
      - Genre
      - IMDb rating
      - Streaming services available (Netflix, Amazon Prime, Hulu, etc.)
      - URL to the movie page on JustWatch

   **b. TV Show Information:**

      - TV show title
      - Release year
      - Genre
      - IMDb rating
      - Streaming services available (Netflix, Amazon Prime, Hulu, etc.)
      - URL to the TV show page on JustWatch

  **c. Scope:**

```
 ` - Scrape data for at least 50 movies and 50 TV shows.
   - You can choose the entry point (e.g., starting with popular movies,
     or a specific genre, etc.) to ensure a diverse dataset.`

```


**2. Data Filtering & Analysis:**

   After scraping the data, use Pandas to perform the following tasks:

   **a. Filter movies and TV shows based on specific criteria:**

   ```
      - Only include movies and TV shows released in the last 2 years (from the current date).
      - Only include movies and TV shows with an IMDb rating of 7 or higher.
```

   **b. Data Analysis:**

   ```
      - Calculate the average IMDb rating for the scraped movies and TV shows.
      - Identify the top 5 genres that have the highest number of available movies and TV shows.
      - Determine the streaming service with the most significant number of offerings.
      
   ```   

**3. Data Export:**

```
   - Dump the filtered and analysed data into a CSV file for further processing and reporting.

   - Keep the CSV file in your Drive Folder and Share the Drive link on the colab while keeping view access with anyone.
```

**Submission:**
```
- Submit a link to your Colab made for the assignment.

- The Colab should contain your Python script (.py format only) with clear
  comments explaining the scraping, filtering, and analysis process.

- Your Code shouldn't have any errors and should be executable at a one go.

- Before Conclusion, Keep your Dataset Drive Link in the Notebook.
```



**Note:**

1. Properly handle errors and exceptions during web scraping to ensure a robust script.

2. Make sure your code is well-structured, easy to understand, and follows Python best practices.

3. The assignment will be evaluated based on the correctness of the scraped data, accuracy of data filtering and analysis, and the overall quality of the Python code.

# **Start The Project**

## **Task 1:- Web Scrapping**
"""

#Installing all necessary labraries
!pip install bs4
!pip install requests

#import all necessary labraries
import requests
from bs4 import BeautifulSoup
import re
import pandas as pd
import numpy as np

"""## **Scrapping Movies Data**"""

def fetch_movie_urls(url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'
    }
    response = requests.get(url, headers=headers)
    if response.status_code != 200:
        return "Failed to retrieve the page, status code:", response.status_code
    soup = BeautifulSoup(response.text, 'html.parser')
    return soup


url = 'https://www.justwatch.com/in/movies?release_year_from=2000'
soup=fetch_movie_urls(url)
print(soup.prettify())

"""## **Fetching Movie URL's**"""

# Write Your Code here
# Extract movie URLs from the soup
movie_links = soup.find_all('a', href=True)

# Filter only links that are movie detail pages
movie_urls = [link['href'] for link in movie_links if '/in/movie/' in link['href']]

# Remove duplicates and prefix with base URL
unique_movie_urls = list(set(['https://www.justwatch.com' + url for url in movie_urls]))

# Limit to 50 unique movies
unique_movie_urls = unique_movie_urls[:50]

# Print sample to verify
print(f"Collected {len(unique_movie_urls)} movie URLs.")
for i, url in enumerate(unique_movie_urls[:5]):
    print(f"{i+1}: {url}")

"""## **Scrapping Movie Title**"""

# Write Your Code here
# List to store movie titles
movie_titles = []

 #Loop through each movie URL and extract the title
for url in unique_movie_urls:
    response = requests.get(url, headers={
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'})

    if response.status_code != 200:
        print(f"Failed to fetch {url}")
        movie_titles.append(None)
        continue

    soup = BeautifulSoup(response.text, 'html.parser')

    # The movie title is usually in an <h1> tag with some class
    title_tag = soup.find('h1')

    if title_tag:
      full_title = title_tag.text.strip()
      # Extract title and year using regex
      match = re.match(r'^(.*)\s+\((\d{4})\)$', full_title)
      if match:
        movie_titles.append(match.group(1))       # Title without year
      else:
        movie_titles.append(full_title)           # Fallback: full title
    else:
      movie_titles.append(None)

# Print the first 5 titles to verify
for i, title in enumerate(movie_titles[:5]):
    print(f"{i+1}. {title}")

"""## **Scrapping release Year**"""

# Write Your Code here
import re

movie_titles = []
release_years = []

for url in unique_movie_urls:
    try:
        response = requests.get(url, headers={
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'
        })

        if response.status_code != 200:
            print(f"Failed to fetch {url}")
            movie_titles.append(None)
            release_years.append(None)
            continue

        soup = BeautifulSoup(response.text, 'html.parser')
        title_tag = soup.find('h1')

        if title_tag:
            full_title = title_tag.text.strip()

            # Extract title and year using regex
            match = re.match(r'^(.*)\s+\((\d{4})\)$', full_title)
            if match:
                movie_titles.append(match.group(1))       # Title without year
                release_years.append(match.group(2))      # Year only
            else:
                movie_titles.append(full_title)           # Fallback: full title
                release_years.append(None)
        else:
            movie_titles.append(None)
            release_years.append(None)

    except Exception as e:
        print(f"Error at {url} -> {e}")
        movie_titles.append(None)
        release_years.append(None)

# Check sample output
for i in range(5):
    print(f"{i+1}. {movie_titles[i]} ({release_years[i]})")

"""## **Scrapping Genres**"""

movie_titles = []
genres = []

for url in unique_movie_urls:
    try:
        response = requests.get(url, headers={
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'
        })
        soup = BeautifulSoup(response.text, 'html.parser')

        # --- Extract Title ---
        title_tag = soup.find('h1')
        if title_tag:
            full_title = title_tag.text.strip()
            match = re.match(r'^(.*)\s+\((\d{4})\)$', full_title)
            movie_titles.append(match.group(1) if match else full_title)
        else:
            movie_titles.append(None)

        # --- Extract Genre ---
        script_tag = soup.find('script', type='application/ld+json')
        if script_tag:
            data = json.loads(script_tag.string)

            genre_field = data.get("genre")
            if isinstance(genre_field, list):
                genres.append(", ".join(genre_field))
            elif isinstance(genre_field, str):
                genres.append(genre_field)
            else:
                genres.append(None)
        else:
            genres.append(None)

    except Exception as e:
        print(f"Error at {url}: {e}")
        movie_titles.append(None)
        genres.append(None)

# Preview results
for i in range(5):
    print(f"{i+1}. Title: {movie_titles[i]}, Genre: {genres[i]}")

"""## **Scrapping IMBD Rating**"""

movie_titles = []
imdb_ratings = []

for url in unique_movie_urls:
    try:
        response = requests.get(url, headers={
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'
        })
        soup = BeautifulSoup(response.text, 'html.parser')

        # --- Extract Title ---
        title_tag = soup.find('h1')
        if title_tag:
            full_title = title_tag.text.strip()
            match = re.match(r'^(.*)\s+\((\d{4})\)$', full_title)
            movie_titles.append(match.group(1) if match else full_title)
        else:
            movie_titles.append(None)

        # --- Extract IMDb rating ---
        imdb_rating = None
        for tag in soup.find_all(['span', 'div', 'a']):
            text = tag.get_text(strip=True)
            # Look for text like 'IMDb 7.5' or '7.2/10'
            if "imdb" in text.lower() and re.search(r'\d\.\d', text):
                match = re.search(r'(\d\.\d)', text)
                if match:
                    imdb_rating = match.group(1)
                    break
            elif re.search(r'\d\.\d/10', text):  # backup pattern
                imdb_rating = text.split('/')[0]
                break

        imdb_ratings.append(imdb_rating)

    except Exception as e:
        print(f"Error at {url}: {e}")
        movie_titles.append(None)
        imdb_ratings.append(None)

# Preview results
for i in range(5):
    print(f"{i+1}. Title: {movie_titles[i]}, IMDb: {imdb_ratings[i]}")

"""## **Scrapping Runtime/Duration**"""

!pip install isodate

import json

movie_titles = []
durations = []

for url in unique_movie_urls:
    try:
        response = requests.get(url, headers={
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'
        })
        soup = BeautifulSoup(response.text, 'html.parser')

        # --- Extract title from <h1> ---
        title_tag = soup.find('h1')
        if title_tag:
            full_title = title_tag.text.strip()
            match = re.match(r'^(.*)\s+\((\d{4})\)$', full_title)
            movie_titles.append(match.group(1) if match else full_title)
        else:
            movie_titles.append(None)

        # --- Extract runtime from JSON (if present) ---
        runtime_minutes = None
        script_tag = soup.find('script', type='application/ld+json')
        if script_tag:
            data = json.loads(script_tag.string)
            duration_iso = data.get("duration")  # e.g., "PT2H10M"

            if duration_iso:
                # Parse ISO 8601 duration to minutes
                hours = re.search(r'(\d+)H', duration_iso)
                minutes = re.search(r'(\d+)M', duration_iso)
                total_minutes = 0
                if hours:
                    total_minutes += int(hours.group(1)) * 60
                if minutes:
                    total_minutes += int(minutes.group(1))
                runtime_minutes = total_minutes

        durations.append(runtime_minutes)

    except Exception as e:
        print(f"Error at {url}: {e}")
        movie_titles.append(None)
        durations.append(None)

# Preview sample results
for i in range(5):
    print(f"{i+1}. Title: {movie_titles[i]}, Runtime: {durations[i]} mins")

"""## **Scrapping Age Rating**"""

import json

movie_titles = []
age_ratings = []

for url in unique_movie_urls:
    try:
        response = requests.get(url, headers={
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'
        })
        soup = BeautifulSoup(response.text, 'html.parser')

        # --- Title extraction ---
        title_tag = soup.find('h1')
        if title_tag:
            full_title = title_tag.text.strip()
            match = re.match(r'^(.*)\s+\((\d{4})\)$', full_title)
            movie_titles.append(match.group(1) if match else full_title)
        else:
            movie_titles.append(None)

        # --- Age rating extraction from ld+json ---
        script_tag = soup.find('script', type='application/ld+json')
        rating = None
        if script_tag:
            try:
                data = json.loads(script_tag.string)
                rating = data.get("contentRating")  # e.g., "PG-13"
            except:
                rating = None

        age_ratings.append(rating)

    except Exception as e:
        print(f"Error at {url}: {e}")
        movie_titles.append(None)
        age_ratings.append(None)

# Preview sample
for i in range(5):
    print(f"{i+1}. Title: {movie_titles[i]}, Age Rating: {age_ratings[i]}")

"""## **Fetching Production Countries Details**"""

# Write Your Code here
import json
import re

movie_titles = []
production_countries = []

for url in unique_movie_urls:
    try:
        response = requests.get(url, headers={
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'
        })
        soup = BeautifulSoup(response.text, 'html.parser')

        # --- Extract Title ---
        title_tag = soup.find('h1')
        if title_tag:
            full_title = title_tag.text.strip()
            match = re.match(r'^(.*)\s+\((\d{4})\)$', full_title)
            movie_titles.append(match.group(1) if match else full_title)
        else:
            movie_titles.append(None)

        # --- Extract Country of Origin from JSON (if available) ---
        country_names = None
        script_tag = soup.find('script', type='application/ld+json')
        if script_tag:
            try:
                data = json.loads(script_tag.string)

                # Some pages use 'countryOfOrigin', others 'productionCompany', or none
                if "countryOfOrigin" in data:
                    countries = data["countryOfOrigin"]
                    if isinstance(countries, list):
                        country_names = ", ".join(
                            [c.get("name") for c in countries if "name" in c])
                    elif isinstance(countries, dict):
                        country_names = countries.get("name")
            except json.JSONDecodeError:
                country_names = None

        production_countries.append(country_names)

    except Exception as e:
        print(f"Error at {url}: {e}")
        movie_titles.append(None)
        production_countries.append(None)

# Preview sample
for i in range(5):
    print(f"{i+1}. Title: {movie_titles[i]}, Country: {production_countries[i]}")

"""## **Fetching Streaming Service Details**"""

# Write Your Code here
import json
import re

movie_titles = []
streaming_services = []

for url in unique_movie_urls:
    try:
        response = requests.get(url, headers={
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'
        })
        soup = BeautifulSoup(response.text, 'html.parser')

        # --- Extract Movie Title ---
        title_tag = soup.find('h1')
        if title_tag:
            full_title = title_tag.text.strip()
            match = re.match(r'^(.*)\s+\((\d{4})\)$', full_title)
            movie_titles.append(match.group(1) if match else full_title)
        else:
            movie_titles.append(None)

        # --- Extract Streaming Services ---
        services = set()

        # Method 1: Check for alt/title of logos
        for img in soup.find_all('img', alt=True):
            alt_text = img['alt'].lower()
            if any(service in alt_text for service in ['netflix', 'prime', 'hotstar', 'disney', 'zee5', 'jio', 'sonyliv', 'hulu', 'apple tv']):
                services.add(img['alt'].strip())

        # Check JSON offers
        script_tag = soup.find('script', type='application/ld+json')
        if script_tag:
            try:
                data = json.loads(script_tag.string)
                offers = data.get("offers")
                if offers:
                    if isinstance(offers, list):
                        for offer in offers:
                            provider = offer.get("seller", {}).get("name")
                            if provider:
                                services.add(provider.strip())
            except:
                pass

        streaming_services.append(", ".join(services) if services else None)

    except Exception as e:
        print(f"Error at {url}: {e}")
        movie_titles.append(None)
        streaming_services.append(None)

# Preview sample
for i in range(5):
    print(f"{i+1}. Title: {movie_titles[i]}, Services: {streaming_services[i]}")

"""## **Now Creating Movies DataFrame**"""

# Write Your Code here
import pandas as pd

# Combine into a dictionary
movies_data = {
    "Title": movie_titles,
    "Release Year": release_years,
    "Genre": genres,
    "IMDb Rating": imdb_ratings,
    "Runtime (mins)": durations,
    "Age Rating": age_ratings,
    "Production Country": production_countries,
    "Streaming Services": streaming_services,
    "JustWatch URL": unique_movie_urls
}

# Create DataFrame
movies_df = pd.DataFrame(movies_data)

# Preview first 5 rows
movies_df.tail(5)



"""## **Scraping TV  Show Data**"""

tv_url = 'https://www.justwatch.com/in/tv-shows?release_year_from=2000'

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'
}

response = requests.get(tv_url, headers=headers)
soup = BeautifulSoup(response.text, 'html.parser')

"""## **Fetching Tv shows Url details**"""

# Write Your Code here
# Extract TV show URLs from <a> tags
tv_links = soup.find_all('a', href=True)
tv_urls = ['https://www.justwatch.com' + link['href']
           for link in tv_links if '/in/tv-show/' in link['href']]

# Remove duplicates
unique_tv_urls = list(set(tv_urls))[:50]  # Limit to 50

# Preview
print(f"Collected {len(unique_tv_urls)} TV show URLs.")
print(unique_tv_urls[:5])

"""## **Fetching Tv Show Title details**"""

# Write Your Code here
import re

tv_titles = []

for url in unique_tv_urls:
    try:
        response = requests.get(url, headers={
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'
        })
        soup = BeautifulSoup(response.text, 'html.parser')

        # Extract title from <h1>
        title_tag = soup.find('h1')
        if title_tag:
            full_title = title_tag.text.strip()
            # Remove year if present in parentheses
            match = re.match(r'^(.*)\s+\((\d{4})\)$', full_title)
            tv_titles.append(match.group(1) if match else full_title)
        else:
            tv_titles.append(None)

    except Exception as e:
        print(f"Error at {url}: {e}")
        tv_titles.append(None)

# Preview
for i in range(5):
    print(f"{i+1}. Title: {tv_titles[i]}")

"""## **Fetching Release Year**"""

# Write Your Code here
import re

tv_titles = []
tv_release_years = []

for url in unique_tv_urls:
    try:
        response = requests.get(url, headers={
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'
        })
        soup = BeautifulSoup(response.text, 'html.parser')

        # Find the title with year in <h1>
        title_tag = soup.find('h1')
        if title_tag:
            full_title = title_tag.text.strip()

            # Extract title and year
            match = re.match(r'^(.*)\s+\((\d{4})\)$', full_title)
            if match:
                tv_titles.append(match.group(1))
                tv_release_years.append(match.group(2))
            else:
                tv_titles.append(full_title)
                tv_release_years.append(None)
        else:
            tv_titles.append(None)
            tv_release_years.append(None)

    except Exception as e:
        print(f"Error at {url}: {e}")
        tv_titles.append(None)
        tv_release_years.append(None)

# Preview sample
for i in range(5):
    print(f"{i+1}. Title: {tv_titles[i]}, Year: {tv_release_years[i]}")

"""## **Fetching TV Show Genre Details**"""

# Write Your Code here
import re
import json

tv_titles = []
tv_genres = []

for url in unique_tv_urls:
    try:
        response = requests.get(url, headers={
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'
        })
        soup = BeautifulSoup(response.text, 'html.parser')

        # --- Title ---
        title_tag = soup.find('h1')
        if title_tag:
            full_title = title_tag.text.strip()
            match = re.match(r'^(.*)\s+\((\d{4})\)$', full_title)
            tv_titles.append(match.group(1) if match else full_title)
        else:
            tv_titles.append(None)

        # --- Genre from JSON ---
        genre_text = None
        script_tag = soup.find('script', type='application/ld+json')
        if script_tag:
            try:
                data = json.loads(script_tag.string)
                genre_field = data.get("genre")

                if isinstance(genre_field, list):
                    genre_text = ", ".join(genre_field)
                elif isinstance(genre_field, str):
                    genre_text = genre_field
            except:
                genre_text = None

        tv_genres.append(genre_text)

    except Exception as e:
        print(f"Error at {url}: {e}")
        tv_titles.append(None)
        tv_genres.append(None)

# Preview sample
for i in range(5):
    print(f"{i+1}. Title: {tv_titles[i]}, Genre: {tv_genres[i]}")

"""## **Fetching IMDB Rating Details**"""

# Write Your Code here
import re
import json

tv_titles = []
tv_imdb_ratings = []

for url in unique_tv_urls:
    try:
        response = requests.get(url, headers={
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'
        })
        soup = BeautifulSoup(response.text, 'html.parser')

        # --- Title ---
        title_tag = soup.find('h1')
        if title_tag:
            full_title = title_tag.text.strip()
            match = re.match(r'^(.*)\s+\((\d{4})\)$', full_title)
            tv_titles.append(match.group(1) if match else full_title)
        else:
            tv_titles.append(None)

        # --- IMDb Rating ---
        rating = None

        # Try ld+json
        script_tag = soup.find('script', type='application/ld+json')
        if script_tag:
            try:
                data = json.loads(script_tag.string)
                rating_data = data.get("aggregateRating", {})
                if rating_data and "ratingValue" in rating_data:
                    rating = rating_data["ratingValue"]
            except:
                pass

        # Fallback to searching HTML
        if not rating:
            for tag in soup.find_all(['span', 'div', 'a']):
                text = tag.get_text(strip=True).lower()
                if "imdb" in text and re.search(r'\d\.\d', text):
                    match = re.search(r'(\d\.\d)', text)
                    if match:
                        rating = match.group(1)
                        break

        tv_imdb_ratings.append(rating)

    except Exception as e:
        print(f"Error at {url}: {e}")
        tv_titles.append(None)
        tv_imdb_ratings.append(None)

# ✅ Preview sample
for i in range(5):
    print(f"{i+1}. Title: {tv_titles[i]}, IMDb Rating: {tv_imdb_ratings[i]}")

"""## **Fetching Age Rating Details**"""

# Write Your Code here
import re
import json

tv_titles = []
tv_age_ratings = []

for url in unique_tv_urls:
    try:
        response = requests.get(url, headers={
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'
        })
        soup = BeautifulSoup(response.text, 'html.parser')

        # --- Extract title ---
        title_tag = soup.find('h1')
        if title_tag:
            full_title = title_tag.text.strip()
            match = re.match(r'^(.*)\s+\((\d{4})\)$', full_title)
            tv_titles.append(match.group(1) if match else full_title)
        else:
            tv_titles.append(None)

        # --- Extract age rating from JSON ---
        age_rating = None
        script_tag = soup.find('script', type='application/ld+json')
        if script_tag:
            try:
                data = json.loads(script_tag.string)
                age_rating = data.get("contentRating")
            except:
                pass

        tv_age_ratings.append(age_rating)

    except Exception as e:
        print(f"Error at {url}: {e}")
        tv_titles.append(None)
        tv_age_ratings.append(None)

# Preview sample
for i in range(5):
    print(f"{i+1}. Title: {tv_titles[i]}, Age Rating: {tv_age_ratings[i]}")

"""## **Fetching Production Country details**"""

# Write Your Code here
import re
import json

tv_titles = []
tv_countries = []

for url in unique_tv_urls:
    try:
        response = requests.get(url, headers={
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'
        })
        soup = BeautifulSoup(response.text, 'html.parser')

        # --- Extract title ---
        title_tag = soup.find('h1')
        if title_tag:
            full_title = title_tag.text.strip()
            match = re.match(r'^(.*)\s+\((\d{4})\)$', full_title)
            tv_titles.append(match.group(1) if match else full_title)
        else:
            tv_titles.append(None)

        # --- Extract production country from ld+json ---
        country = None
        script_tag = soup.find('script', type='application/ld+json')
        if script_tag:
            try:
                data = json.loads(script_tag.string)
                country_data = data.get("countryOfOrigin")

                if isinstance(country_data, list):
                    country = ", ".join(c.get("name") for c in country_data if "name" in c)
                elif isinstance(country_data, dict):
                    country = country_data.get("name")
            except:
                country = None

        tv_countries.append(country)

    except Exception as e:
        print(f"Error at {url}: {e}")
        tv_titles.append(None)
        tv_countries.append(None)

# Preview sample
for i in range(5):
    print(f"{i+1}. Title: {tv_titles[i]}, Country: {tv_countries[i]}")

"""## **Fetching Streaming Service details**"""

# Write Your Code here
import re
import json

tv_titles = []
tv_streaming_services = []

for url in unique_tv_urls:
    try:
        response = requests.get(url, headers={
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'
        })
        soup = BeautifulSoup(response.text, 'html.parser')

        # --- Extract title ---
        title_tag = soup.find('h1')
        if title_tag:
            full_title = title_tag.text.strip()
            match = re.match(r'^(.*)\s+\((\d{4})\)$', full_title)
            tv_titles.append(match.group(1) if match else full_title)
        else:
            tv_titles.append(None)

        # --- Extract streaming services ---
        services = set()

        # from <img alt="Netflix"> etc.
        for img in soup.find_all('img', alt=True):
            alt = img['alt'].strip().lower()
            if any(platform in alt for platform in ['netflix', 'prime', 'hotstar', 'zee5', 'jio', 'sonyliv', 'hulu', 'apple tv']):
                services.add(img['alt'].strip())


        tv_streaming_services.append(", ".join(services) if services else None)

    except Exception as e:
        print(f"Error at {url}: {e}")
        tv_titles.append(None)
        tv_streaming_services.append(None)

# Preview
for i in range(5):
    print(f"{i+1}. Title: {tv_titles[i]}, Streaming Services: {tv_streaming_services[i]}")

"""## **Fetching Duration Details**"""

# Write Your Code here
import re
import json

tv_titles = []
tv_durations = []

for url in unique_tv_urls:
    try:
        response = requests.get(url, headers={
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'
        })
        soup = BeautifulSoup(response.text, 'html.parser')

        # --- Extract Title ---
        title_tag = soup.find('h1')
        if title_tag:
            full_title = title_tag.text.strip()
            match = re.match(r'^(.*)\s+\((\d{4})\)$', full_title)
            tv_titles.append(match.group(1) if match else full_title)
        else:
            tv_titles.append(None)

        # --- Extract Duration ---
        duration_minutes = None
        script_tag = soup.find('script', type='application/ld+json')
        if script_tag:
            try:
                data = json.loads(script_tag.string)
                duration_str = data.get("duration")  # e.g., "PT1H2M"

                if duration_str:
                    hours = re.search(r'(\d+)H', duration_str)
                    minutes = re.search(r'(\d+)M', duration_str)
                    total = 0
                    if hours:
                        total += int(hours.group(1)) * 60
                    if minutes:
                        total += int(minutes.group(1))
                    duration_minutes = total if total > 0 else None

            except:
                duration_minutes = None

        tv_durations.append(duration_minutes)

    except Exception as e:
        print(f"Error at {url}: {e}")
        tv_titles.append(None)
        tv_durations.append(None)

# Preview sample
for i in range(5):
    print(f"{i+1}. Title: {tv_titles[i]}, Duration: {tv_durations[i]} minutes")

"""## **Creating TV Show DataFrame**"""

# Write Your Code here
import pandas as pd

# Ensure all lists have same length
min_len = min(
    len(tv_titles), len(tv_release_years), len(tv_genres), len(tv_imdb_ratings),
    len(tv_durations), len(tv_age_ratings), len(tv_countries),
    len(tv_streaming_services), len(unique_tv_urls)
)

# Slice all lists to the same length
tv_data = {
    "Title": tv_titles[:min_len],
    "Release Year": tv_release_years[:min_len],
    "Genre": tv_genres[:min_len],
    "IMDb Rating": tv_imdb_ratings[:min_len],
    "Runtime (mins)": tv_durations[:min_len],
    "Age Rating": tv_age_ratings[:min_len],
    "Production Country": tv_countries[:min_len],
    "Streaming Services": tv_streaming_services[:min_len],
    "JustWatch URL": unique_tv_urls[:min_len]
}

# Create the DataFrame
tv_df = pd.DataFrame(tv_data)

# Preview
tv_df.head(5)



"""## **Task 2 :- Data Filtering & Analysis**"""

# Write Your Code here
# Released in the last 2 years (from today)
# IMDb rating ≥ 7

from datetime import datetime

# Convert release year to int
tv_df['Release Year'] = pd.to_numeric(tv_df['Release Year'], errors='coerce')

# Convert IMDb rating to float
tv_df['IMDb Rating'] = pd.to_numeric(tv_df['IMDb Rating'], errors='coerce')

# Get current year
current_year = datetime.now().year

# Filter based on conditions
filtered_tv_df = tv_df[
    (tv_df['Release Year'] >= current_year - 2) &
    (tv_df['IMDb Rating'] >= 7)
]

# Preview filtered TV shows
print(f"Filtered TV Shows: {len(filtered_tv_df)}")
filtered_tv_df.head()

"""## **Calculating Mean IMDB Ratings for both Movies and Tv Shows**"""

# Write Your Code here
# Convert ratings to numeric in case they are strings
movies_df['IMDb Rating'] = pd.to_numeric(movies_df['IMDb Rating'], errors='coerce')
tv_df['IMDb Rating'] = pd.to_numeric(tv_df['IMDb Rating'], errors='coerce')

# Drop NaN and calculate means
mean_movie_rating = movies_df['IMDb Rating'].dropna().mean()
mean_tv_rating = tv_df['IMDb Rating'].dropna().mean()

print(f"Average IMDb Rating for Movies: {mean_movie_rating:.2f}")
print(f"Average IMDb Rating for TV Shows: {mean_tv_rating:.2f}")

"""## **Finding Predominant Streaming Service**"""

# Write Your Code here
from collections import Counter

def get_top_streaming_service(df, label):
    service_list = []

    for s in df['Streaming Services'].dropna():
        service_list.extend([srv.strip() for srv in s.split(',')])

    service_counts = Counter(service_list)
    top_service = service_counts.most_common(1)

    print(f"\n Predominant Streaming Service in {label}:")
    if top_service:
        print(f"{top_service[0][0]} ({top_service[0][1]} titles)")
    else:
        print("No data available.")

# For Movies
get_top_streaming_service(movies_df, "Movies")

# For TV Shows
get_top_streaming_service(tv_df, "TV Shows")

#Let's Visvalize it using word cloud
!pip install wordcloud

from wordcloud import WordCloud
import matplotlib.pyplot as plt
from collections import Counter

def generate_wordcloud(df, label):
    service_list = []

    for s in df['Streaming Services'].dropna():
        service_list.extend([srv.strip() for srv in s.split(',')])

    service_counts = Counter(service_list)

    wc = WordCloud(width=800, height=400, background_color='white', colormap='viridis')
    wc.generate_from_frequencies(service_counts)

    # Plot
    plt.figure(figsize=(10, 5))
    plt.imshow(wc, interpolation='bilinear')
    plt.axis('off')
    plt.title(f"{label} - Streaming Services Word Cloud", fontsize=16)
    plt.show()

# Word Cloud for Movies
generate_wordcloud(movies_df, "Movies")

# Word Cloud for TV Shows
generate_wordcloud(tv_df, "TV Shows")

"""## **Task 3 :- Data Export**"""

#saving final dataframe as Final Data in csv format
movies_df.to_csv("justwatch_movies_data.csv", index=False)

#saving filter data as Filter Data in csv format
tv_df.to_csv("justwatch_tv_data.csv", index=False)

"""# ***Congratulations!!! You have completed your Assignment.***"""